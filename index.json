
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I’m currently a PhD student at Virginia Tech.\nI have 3 years of working experience in deep learning and reinforcement learning. I worked for AutoX and Jidu Automobile on trajectory prediction and planning of autonomous vehicles. Before that, I worked for Huawei, mainly on combinatorial optimization, reinforcement learning and trajectory prediction.\nI received my master degree from EIT Digital’s Double Degree Program in Visual Computing and Commmunication (University of Trento/Aalto University) in 2020 and my bachelor degree from Tongji University in Transportation Engineering in 2018.\nDownload my resumé.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I’m currently a PhD student at Virginia Tech.\nI have 3 years of working experience in deep learning and reinforcement learning. I worked for AutoX and Jidu Automobile on trajectory prediction and planning of autonomous vehicles.","tags":null,"title":"Yangzhe Kong","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://yanko96.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Yangzhe Kong"],"categories":["Research Proposal"],"content":"A PDF version is shown below. Or you can download it here. This browser does not support PDFs. Please download the PDF to view it: Download PDF.\n","date":1662681600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662681600,"objectID":"c61306f4215ef76a46516e5640e28db7","permalink":"https://yanko96.github.io/post/trajectory_prediction_rp/","publishdate":"2022-09-09T00:00:00Z","relpermalink":"/post/trajectory_prediction_rp/","section":"post","summary":"Summary of my understanding of potential future work plan of trajectory prediction","tags":["Research Proposal","Trajectory Prediction","Autonomous Driving"],"title":"Research Proposal on Trajectory Prediction","type":"post"},{"authors":null,"categories":null,"content":"This project was done at research team of perception team at ADAS, Huawei Technologies Co., Ltd.\nMotivation Although most of the autonomous driving algorithm follows the pipeline of “detection-tracking-prediction”, it can be deficient since each stage will accumulate the errors previous stages have made. In some cases, the errors will be amplified and result in disastrous accidents. Moreover, since in later stages, the features that previous stages used to produce the results are not available anymore, which makes correcting erroneous outputs infeasible. Therefore, instead of exploiting rule-based sensor fusion and the sequential pipeline “detection-tracking-prediction”, our research team decided to explore Hydranet-like networks that fuse features, detect objects, track objects and predict object trajectory. Specifically, detecting, tracking and predicting are completed with different heads that connected to the same backbone network that fuses features from different sensors.\nTo testify the feasibility, we want to verify if it’s doable to predict trajectory based on raw point cloud data. And that’s how this project came into being.\nModel Structure Backbone Structure We adopt the detection model from detection team. It’s a UNet-like model and its detection head resembles CenterPoint. A lot of somplifications have been done to accelerate the model and make it compatible for AI chips on vehicles. One thing worth noting is that, instead of binary voxels, the model divides the space into fixed-size voxels and compute 4 features for each voxel: Max Z, Min Z, Mean Intensity, No. points.\nTNT We first crop rasterized HDMap and feature maps from detection backbone, according to the obstacle position. Then we merge the crop from HDMap and the crop from detection backbone feature maps, to generate the feature for each obstacle, which is then feeded into TNT. The 3 stages of TNT remain unchanged.\nOverall Structure Here’s a figure that illustrates the overall structure of the point cLoud-based TNT.\nDataset Since we use point cloud dataset, there’s a huge problem. The distribution of trajectories in the dataset is ill-posed. More than 20% of obstacles in the dataset are either going straight or staying still. To tackle this problem, we use 3 tricks:\nresample the dataset: upsample difficult scenarios and downsample easy ones. use differentiated loss: higher coefficients for difficult scenarios and lower for easy ones. do data augmentation: flip, rotate, etc. Demo I’m very sorry that due to the regulation of Huawei, I cannot show any source code or finished effect of the model. These demo videos are the only things that I can provide here.\nConclusion Due to the volumn of point cloud dataset, it contains far less scenarios than ordinary trajectory prediction dataset. However, the performance is considerable as most peaks of multi-modal predictions are correctly assigned. We belive there’s still lots of space for improvement, if we use larger dataset and add interaction module in the model.\n","date":1648684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648684800,"objectID":"c18d481c99b8cb3b0ccc46cb9fe46e0c","permalink":"https://yanko96.github.io/project/point_cloud_based_tnt/","publishdate":"2022-03-31T00:00:00Z","relpermalink":"/project/point_cloud_based_tnt/","section":"project","summary":"Point Cloud-based TNT for Trajectory Prediction","tags":["Deep Learning","Autonomous Driving"],"title":"Point Cloud-based TNT for Trajectory Prediction","type":"project"},{"authors":null,"categories":null,"content":"The project was done at Huawei Technologies Co., Ltd., and is vailable on Arxiv.\nTang Q, Kong Y, Pan L, Lee C. Learning to Solve Soft-Constrained Vehicle Routing Problems with Lagrangian Relaxation. arXiv preprint arXiv:2207.09860. 2022 Jul 20. Paper [PDF]\nMotivation Exact algorithms is not always computationally efficient enough to deploy, especially on large scenarios with complex constraints. Other methods like heuristics or meta-heuristics solvers are also faced with the same dilemma. Vehicle Routing Problems (VRPs) in real-world applications often come with various constraints, therefore bring additional computational challenges to classical algorithms like exact solution methods or heuristic search approaches. The recent idea to learn heuristic move patterns from sample data has become increasingly promising to reduce solution developing costs. However, using learning-based approaches to address more types of constrained VRP remains a challenge.\nTrajectory Shaping We improve the model performance by intervening the trajectory generation process to boost the quality of the agent’s training information. The motivation is similar to modifying the expression of return. Due to the large search space and the sparsity of optima, guiding the agent to explore and learn the ’good’ actions can be very slow or easily trapped into local optima, especially if the initial state solution is far from the true global optimum. With the underlying model being deterministic and we can easily obtain the next state’s reward and cost, we suggest a post-action rejection rule deciding whether to reject the candidate solution respectively when non-improved and improved solutions are found to modify the generated trajectories.\nModified Return The expression of $G_{t}$ is specially designed to encourage better performance in soft-constrained VRPs with 2-exchange moves. First, the immediate reward is penalized by the immediate cost such that the agent is encouraged to find better moves while balancing the reward and cost with iteratively updated $\\lambda$s. In addition, We calculate the cumulative value using the maximum value of all pairs of subsequent moves from $s_{t}$ to $s_{t’}$ instead of a summation over all consecutive moves from $s_{t}$ to $s_{t+1}$ as in the $Return$ definition. “Bad” operations that do not improve the objective function will be suppressed, while only the ‘good’ actions are rewarded with the $\\max$ function. It also tends to decorrelate the effect of a series of historical operations so that the agent is less affected by locally optimal trajectories. To sum up, we apply such modification to better mimic the heuristic search process by encouraging more immediate and effective actions that improve the cost-penalized objective function. The following figure provides a visual representation of the definition of $G_t$.\nPerformance We observed slightly better performance than Google OR-Tools and close performance to LKH-3.\nConcerns on the dataset Although generation of VRP/CVRP datasets is pretty intuitive, VRPTW datasets are tricky to deal with. In our implementation we generate first a CVRP scenario and then a CVRP solution by heuristics. Time windows are then generated according to arrival time in the CVRP solution to make sure that there is at least one valid sulution. However, we believe that there are better ways to generate VRPTW/CVRPTW datsaets.\n","date":1622419200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622419200,"objectID":"6e93c082b179ded6d3b603f13384831d","permalink":"https://yanko96.github.io/project/learn_cvrptw/","publishdate":"2021-05-31T00:00:00Z","relpermalink":"/project/learn_cvrptw/","section":"project","summary":"Learning to Solve Soft-Constrained Vehicle Routing Problems with Lagrangian Relaxation","tags":["Deep Learning","Reinforcement Learning","Combinatorial Optimization"],"title":"Learning to Solve Soft-Constrained Vehicle Routing Problems with Lagrangian Relaxation","type":"project"},{"authors":["Qiaoyue Tang","Yangzhe Kong","Lemeng Pan","Choonmeng Lee"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1622419200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622419200,"objectID":"ce64245b03d23be01d7d55d8d9d9bf9f","permalink":"https://yanko96.github.io/publication/learn_cvrptw/","publishdate":"2022-07-20T00:00:00Z","relpermalink":"/publication/learn_cvrptw/","section":"publication","summary":"Vehicle Routing Problems (VRPs) in real-world applications often come with various constraints, therefore bring additional computational challenges to exact solution methods or heuristic search approaches. The recent idea to learn heuristic move patterns from sample data has become increasingly promising to reduce solution developing costs. However, using learning-based approaches to address more types of constrained VRP remains a challenge. The difficulty lies in controlling for constraint violations while searching for optimal solutions. To overcome this challenge, we propose a Reinforcement Learning based method to solve soft-constrained VRPs by incorporating the Lagrangian relaxation technique and using constrained policy optimization. We apply the method on three common types of VRPs, the Travelling Salesman Problem with Time Windows (TSPTW), the Capacitated VRP (CVRP) and the Capacitated VRP with Time Windows (CVRPTW), to show the generalizability of the proposed method. After comparing to existing RL-based methods and open-source heuristic solvers, we demonstrate its competitive performance in finding solutions with a good balance in travel distance, constraint violations and inference speed.","tags":[],"title":"Learning to Solve Soft-Constrained Vehicle Routing Problems with Lagrangian Relaxation","type":"publication"},{"authors":null,"categories":null,"content":"\rThe project was done in Nokia Bell Labs. The paper Path-Link Graph Neural Network for IP Network Performance Prediction is published in 2021 IFIP/IEEE International Symposium on Integrated Network Management (IM).\nKong, Y., Petrov, D., Räisänen, V. and Ilin, A., 2021, May. Path-Link Graph Neural Network for IP Network Performance Prediction. In 2021 IFIP/IEEE International Symposium on Integrated Network Management (IM) (pp. 170-177). IEEE. Paper [PDF]\nMotivation Dynamic resource provisioning and quality assurance for the plethora of end-to-end slices running over 5G and B5G networks require advanced modeling capabilities. Graph Neural Networks (GNN) have already proven their efficiency for network performance prediction. We verified a SOTA model RouteNet by a new implementation in the PyTorch ML library. Next, with the aims to improve accuracy and scalability, an alternative Path-Link neural network (PLNet) architecture is proposed and evaluated.\nPerformance We observed slightly better accuracy and better generalization.\nImproved Scalability Largely improved scalability is observed.\nFuture Works There are several future directions for the continuation of this study. Firstly, RouteNet and PLNet models have good potential for reinforcement learning. For example, dynamic resource allocation. Secondly, although we consider more generic scenarios than 5G in this paper, it is still a good starting point for going further into more specific 5G scenarios. That is to say, extending the comparison and application of the models on more extensive networks and in the context of 5G scenarios like end-to-end slicing are also promising research topics.\n","date":1596153600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596153600,"objectID":"59e3dd82d181f5dcb4fc9524d856bac9","permalink":"https://yanko96.github.io/project/plnet/","publishdate":"2020-07-31T00:00:00Z","relpermalink":"/project/plnet/","section":"project","summary":"Path-Link Graph Neural Network for IP Network Performance Prediction","tags":["Deep Learning","Graph Neural Network"],"title":"Path-Link Graph Neural Network for IP Network Performance Prediction","type":"project"},{"authors":["Yangzhe Kong","Dmitry Petrov","Vilho Raisanen","Alexander Ilin"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"4e268a26c6dde41bdaa7149f4a65e9e9","permalink":"https://yanko96.github.io/publication/plnet/","publishdate":"2021-05-17T00:00:00Z","relpermalink":"/publication/plnet/","section":"publication","summary":"Dynamic resource provisioning and quality assurance for the plethora of end-to-end slices running over 5G and B5G networks require advanced modeling capabilities. Graph Neural Networks (GNN) have already proven their efficiency for network performance prediction. GNN architecture matches well the structures usually met in communications networks. In this paper, the focus is on the IP transport network as one of the end-to-end 5G architecture domains. The recently published RouteNet GNN is taken as a reference and starting point for our study. RouteNet performance is verified by a new implementation in the PyTorch ML library. Next, an alternative Path-Link neural network (PLNet) architecture is proposed and evaluated. After hyper-parameter tuning for both models, the results show that PLNet and RouteNet achieve a similar accuracy level. The advantage of PLNet is in parallel architecture. It is demonstrated that its inference speed is not sensitive to the length of the network's paths.","tags":[],"title":"Path-Link Graph Neural Network for IP Network Performance Prediction","type":"publication"},{"authors":null,"categories":null,"content":"This project served as the final project of course ELEC-E8125–Reinforcement-learning D. The code is available here\nWimblepong is a two player version of the pong-v0 OpenAI Gym environment developed by Intelligent Robotics group at Aalto University, Finland.\nMotivation In this project, we were asked to develop an agent for wimblepong and the agents will be tested in a battle royale. In addition, we have 2 options for state space: the visual observation or the encoded vector of the state. Altough many classmates chose to clone github repos of SOTA algorithms such as TRPO, PPO and Dueling Deep Q Networks, I decided to challenge myself and verify one of my questions: Will supervised pretained models help accelerate divergence of reinforcement learning agents? Therefore, I chose to use visual observations and first train a VAE to encode the visual observation, then train an A2C agent of which the input is the encoded state from the VAE encoder.\nFor sure A2C cannot be better than fancier algorithms, I’m still proud of myself, for bringing up ideas and verifying them independently.\nPretrained CNN-VAE A CNN-VAE is pre-trained on collected observations of the wimblepong environment in order to accelerate the converge of the agent training. The VAE adopts a similar model strcture as ResNet. Some of the results on the test set are shown below.\nA2C Agent The encoder of the Agent is loaded from the checkpoint of the encoder of the pre-trained CNN-VAE. Then the agent is trained by A2C algorithm with entropy loss to encourage exploration. With pre-trained VAE loaded as the encoder, the convergence of the agent is accelerated as the following figures show (green paddle is the agent).\nConclusion The pretrained encoder did help accelerate the convergence. However, there are several reasons why I don’t recommend doing so:\nThere’s a big gap between reconstructing the observations and predicting reliable actions and q-values. This makes pretrained model not completely plug-and-play for RL tasks. I spent many efforts selecting most suitable checkpoints and learning rates. It’s not so worthwhile, especially considering that it only accelerate a relatively small amount of training time, but can hardly boost the performance. The model structure of VAE is not necessarily the best for RL models. Exploration is the most crucial for RL. Not these tricks (that are not helpful for exploration). Anyways, it’s still an interesting experience for me.\n","date":1576454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576454400,"objectID":"5fe869c91518159045333c5977fb217c","permalink":"https://yanko96.github.io/project/a2c_pretrain/","publishdate":"2019-12-16T00:00:00Z","relpermalink":"/project/a2c_pretrain/","section":"project","summary":"A2C Agent for playing Wimblepong with pretrained VAE as the encoder","tags":["Deep Learning","Reinforcement Learning"],"title":"A2C Agent for playing Wimblepong with pretrained VAE as the encoder","type":"project"},{"authors":null,"categories":null,"content":"This project served as the final project of course CS-E5710 Bayesian Data Analysis at Aalto University. The code is available here.\n","date":1576368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576368000,"objectID":"f3400194cb792cf7b55d2aa945027d33","permalink":"https://yanko96.github.io/project/bda/","publishdate":"2019-12-15T00:00:00Z","relpermalink":"/project/bda/","section":"project","summary":"Bayesian Data Analysis: mtcars","tags":["Bayesian Data Analysis"],"title":"Bayesian Data Analysis: mtcars","type":"project"},{"authors":null,"categories":null,"content":"This project served as the final project of course CS-E5740 Complex Networks, Aalto University. The code is available here, the final report is available here.\n","date":1576368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576368000,"objectID":"410af048e35382c2309305a469687c6f","permalink":"https://yanko96.github.io/project/complex_network/","publishdate":"2019-12-15T00:00:00Z","relpermalink":"/project/complex_network/","section":"project","summary":"Final Project for CS-E5740 Complex Networks, Aalto University","tags":["Complex Network"],"title":"Complex Network Final Project","type":"project"},{"authors":null,"categories":null,"content":"The project was done at University of Trento, under the supervision of Prof. Farid Melgani. I have had a comprehensive understanding of the reasons begind the shift from more theoretically complete and interpretable models such as Bolzmann Machine, Belief Nets, Markov Random Fields, etc, to more practicle models like Neural Networks. However, I do believe that looking for inspirations from other fields is still very promising for the development of machine learning.\n","date":1559260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559260800,"objectID":"23c380d43f1b75a953e015ce5448af3e","permalink":"https://yanko96.github.io/project/dbm/","publishdate":"2019-05-31T00:00:00Z","relpermalink":"/project/dbm/","section":"project","summary":"Literature Review for Deep Bolzmann Machine and Deep Belief Nets, done as the final project of Recognition Systems at University of Trento","tags":["Machine Learning","Bolzmann Machine"],"title":"Literature Review for Deep Bolzmann Machine and Deep Belief Nets","type":"project"},{"authors":["Yangzhe Kong","Ziqing Du"],"categories":[],"content":"Bayesian Data Analysis Project Report Yangzhe Kong, Ziqing Du\nDataset: mtcars The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models).\nMiles per gallon (a measure of fuel consumption) Number of cylinders Displacement (the total volume of the cylinders) Gross horsepower Rear axle ratio (related to towing capabilities) Weight Quarter mile time (how fast the car can traverse a quarter mile) Shape of the engine - straight vs V-shaped Transmission - automatic vs manual Number of forward gears Number of carburetors Data Exploration First convert to metric units\nfuel consumption: From Miles per US gallon to Litres per 100 km Weight: From pound to ton Displacement: From inch to litre\nThen normalize all data into the range $[0,1]$ except for engine type and transmission type as they are already in the range $[0,1]$ Model Formulation Since there’s no clear need for non-linearity as stated above, we can use bayesian linear regression, i.e., $$y ∼ N(α + βX, σ²)$$\nwhere y is 1/4 mile time, X is the matrix of predictor variables and α, β are the intercept and regression coefficients, respectively\nWeakly informative priors\nThe rule of thumb for weakly informative distributions is that the standard deviation of the posterior distribution should be less than 0.1 times that of the prior.\nalpha ~ cauchy(0,10); beta ~ student_t(3,0,2); sigma ~ normal(0,10); Analysis Problem: What are the best variables that can be used to predict car performance?\nVariables: For multivariate model 1, horsepower, number of carburetors, car weight, transmission type and shape of the engine are the variables X. For multivariate model 2, displacement, car weight, shape of the engine, number of carburetors would be used as variables X. And for multivariate model 3, all variables will be used. Separate linear modeling stan_separate_model = \u0026#39; data { int\u0026lt;lower=0\u0026gt; N; vector[N] x; vector[N] y; } parameters { real alpha; real beta; real\u0026lt;lower=0\u0026gt; sigma; } transformed parameters{ vector[N] mu; mu = alpha + beta*x; } model { alpha ~ cauchy(0,10); beta ~ student_t(3,0,2); sigma ~ normal(0, 10); y ~ normal(mu, sigma); } // Log likelihoods genereated for LOO generated quantities { vector[N] log_lik; for (i in 1:N) log_lik[i] = normal_lpdf(y[i] |alpha+x[i]*beta , sigma); }\u0026#39; stan_nlin_model1 = \u0026#39; data { int\u0026lt;lower=0\u0026gt; n; vector[n] hp; vector[n] wt; vector[n] vs; vector[n] am; vector[n] carb; vector[n] qsec; } parameters { real alpha; real beta_hp; real beta_wt; real beta_vs; real beta_am; real beta_carb; real\u0026lt;lower=0\u0026gt; sigma; } transformed parameters{ vector[n] mu; mu = alpha + beta_hp*hp + beta_wt*wt + beta_vs*vs + beta_am*am + beta_carb*carb; } model { alpha ~ cauchy(0,10); beta_wt ~ student_t(3,0,2); beta_hp ~ student_t(3,0,2); beta_am ~ student_t(3,0,2); beta_vs ~ student_t(3,0,2); beta_carb ~ student_t(3,0,2); sigma ~ normal(0, 10); qsec ~ normal(mu, sigma); } // Log likelihoods genereated for LOO generated quantities { vector[n] log_lik; for (i in 1:n) log_lik[i] = normal_lpdf(qsec[i] |mu[i] , sigma); }\u0026#39; stan_nlin_model2 = \u0026#39; data { int\u0026lt;lower=0\u0026gt; n; vector[n] disp; vector[n] wt; vector[n] vs; vector[n] carb; vector[n] qsec;} parameters { real alpha; real beta_disp; real beta_wt; real beta_vs; real beta_carb; real\u0026lt;lower=0\u0026gt; sigma;} transformed parameters{ vector[n] mu; mu = alpha + beta_disp*disp + beta_wt*wt +beta_vs*vs + beta_carb*carb;} model { alpha ~ cauchy(0,10); beta_disp ~ student_t(3,0,2); beta_wt ~ student_t(3,0,2); beta_vs ~ student_t(3,0,2); beta_carb ~ student_t(3,0,2); sigma ~ normal(0, 10); qsec ~ normal(mu, sigma); } // Log likelihoods genereated for LOO generated quantities { vector[n] log_lik; for (i in 1:n) log_lik[i] = normal_lpdf(qsec[i] |mu[i] , sigma); }\u0026#39; stan_nlin_model3 = \u0026#39; data { int\u0026lt;lower=0\u0026gt; n; vector[n] lphkm; vector[n] cyl; vector[n] disp; vector[n] hp; vector[n] drat; vector[n] wt; vector[n] vs; vector[n] am; vector[n] gear; vector[n] carb; vector[n] qsec;} parameters { real alpha; real beta_lphkm; real beta_cyl; real beta_disp; real beta_hp; real beta_drat; real beta_wt; real beta_vs; real beta_am; real beta_gear; real beta_carb; real\u0026lt;lower=0\u0026gt; sigma;} transformed parameters{ vector[n] mu; mu = alpha + beta_lphkm*lphkm + beta_cyl* cyl + beta_disp * disp + beta_hp*hp + beta_drat* drat + beta} model { alpha ~ cauchy(0,10); beta_lphkm ~ student_t(3,0,2); beta_cyl ~ student_t(3,0,2); beta_hp ~ student_t(3,0,2); beta_drat ~ student_t(3,0,2); beta_wt ~ student_t(3,0,2); beta_am ~ student_t(3,0,2); beta_vs ~ student_t(3,0,2); beta_gear ~ student_t(3,0,2); beta_carb ~ student_t(3,0,2); sigma ~ normal(0, 10); qsec ~ normal(mu, sigma);} // Log likelihoods genereated for LOO generated quantities { vector[n] log_lik; for (i in 1:n) log_lik[i] = normal_lpdf(qsec[i] |mu[i] , sigma);}\u0026#39; Convergence diagnostics - Rhat values / ESS LOO-cv Posterior Distributions Quarter mile time predictive distributions Residuals Statistics …","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"5149c77866c420f4f491acfb19e57e79","permalink":"https://yanko96.github.io/slides/bda/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/bda/","section":"slides","summary":"Bayesian Data Analysis Project Report","tags":["Bayesian Data Analysis"],"title":"Slides","type":"slides"},{"authors":["Yangzhe Kong"],"categories":[],"content":"Deep Bolzmann Machine Yangzhe Kong\nBoltzmann Machines Network is symmetrically connected Allow connection between visible and hidden units Each binary unit makes stochastic decision to be either on or off The configuration of the network dictates its “energy”\nAt the equilibrium state, the likelihood is defined as the exponentiated negative energy, known as the Boltzmann distribution\nThe joint probability of the variable 𝑋 is derived by Boltzmann Distribution as follows, Where Z is the Partition Function. $$p(\\mathbf{x}=\\frac{1}{Z} exp(\\frac{-E(\\mathbf{x})}{T}))$$\nEnergy Function is defined as $$E(\\mathbf{x})\\overset{\\Delta}{=}E(\\mathbf{X}=\\mathbf{x})=-(\\sum_{i\u0026lt;j} w_{ij}x_ix_j+\\sum_{i}b_ix_i)$$ where $𝑤_𝑖𝑗$s are connection weights, $x_i\\in{0,1}$ expresses the state of the variable and $𝑏_𝑖$ is the bias of variable $x_i$ Two problems: Given $w_{ij}$s and biases, how to achieve thermal equilibrium of $P(\\mathbf{X})$ over all possible network config Given $\\mathbf{X}$, learn $w_{ij}$s and biases to maximize $P(\\mathbf{X})$ Problem 1: How to achieve equilibrium\nWe can use Gibbs Sampling The conditional probability of the variable $x$ can be derived as follows $$\rp(x_i=1|\\mathbf{X}_{\\backslash i} )=\\sigma(\\frac{\\sum_j(w_{ij} x_i+b_i)}{T})\r$$\r$$\rp(x_i=0│\\mathbf{X}_{\\backslash i} )=1−p(x_i=0│\\mathbf{X}_{\\backslash i} )\r$$\rThe speed of convergence is related to the temperature 𝑇. When $T→\\infty, p(x_i=1│\\mathbf{x}_(\\backslash i) )→0.5$.\nWhen $𝑇→0$,\n$$\rif \\Delta E_i(\\mathbf{X}_(\\backslash i) )\u0026gt;0, p(x_i=1│\\mathbf{X}_(\\backslash i) )→1\r$$\r$$\rif \\Delta E_i(\\mathbf{X}_(\\backslash i) )\u0026lt;0, p(x_i=1│\\mathbf{X}_(\\backslash i) ) →0\r$$\rIt means that when $𝑇→0$, the whole system change from being dynamic to deterministic. We can use Simulated Annealing Algorithm to introduce some randomness to jump out from the local minimum by setting $x_i$ to 1 with a probability of $\r\\sigma((\\Delta E_i (\\mathbf{X}_(\\backslash i) ))/T)\r$\rwhen $\r\\Delta E_i (\\mathbf{X}_(\\backslash i) )\u0026lt;0\r$\rProblem 2: how to learn the parameters\nWithout loss of generalty, let us assume that variables in Boltzmann Machine consist of visible variables $𝐯∈{𝟎,𝟏}^𝒎$ and hidden variables $h\\in{0,1}^n$. Given a set of visible variables $\\mathbf{D}={\\mathbf{v} ̂^{((1) )},\\mathbf{v} ̂^{((2) )},\\cdots,\\mathbf{v} ̂^{((𝑁) )} }$, our goal is to find the $𝑾$ that can maximize the log likelihood of the visible variables $$\rℒ(𝒟│𝑊,b)=\\frac{1}{𝑁} ∑_{(𝑛=1)^𝑁}log⁡(𝑝(𝐯 ̂^{((𝒏))} |𝑊,𝑏))\r$$\rAfter some calculations, we can get the derivatives of $w_{ij}$ and $b_{i}$, $$\r\\frac{\\nabla\\mathcal{L}(\\mathcal{D}│\\mathbf{W},b)}{\\nabla w_{ij}}=\\lt x_ix_j \\gt _{data}−\\lt x_ix_j \\gt _{model}\r$$\r$$\r\\frac{\\nabla\\mathcal{L}(\\mathcal{D}│\\mathbf{W},b)}{\\nabla b_i}=\\lt x_ix_j \\gt _{data}−\u0026lt;\\lt x_ix_j \\gt _{model}\r$$\rIf gradient ascent is used, update rules can be written like this(update rule for biases is similar) $$\rw_{ij}\\leftarrow w_{ij}+\\alpha (\\lt x_ix_j \\gt _{data}− \\lt x_ix_j \\gt _{model})\r$$\rPositive Phase:\nClamp a data vector on the visible units and set the hidden units to random binary state. Update the hidden units one at a time until the network reaches thermal equilibrium at a temperature of 1. Sample $\u0026lt;x_ix_j\u0026gt;_{data}$ for every connected pair of units Repeat for all data vectors in the training set and average. Negative Phase:\nSet all the units to random binary states Update the units one at a time until the network reaches thermal equilibrium at a temperature of 1. Sample $\u0026lt;x_ix_j\u0026gt;_{model}$ for every connected pair of units Repeat many times and average to get good estimates Restricted Boltzmann Machines A simple unsupervised learning module; Only one layer of hidden units and one layer of visible units; No connection between hidden units nor between visible units; i.e. a special case of Boltzmann Machine; Edges are still undirected or bi-directional e.g., an RBM with 2 visible and 3 hidden units: Energy Function is defined as follows $$\rE(v,h)=−\\sum_i a_iv_i−sum_i b_ih_i−\\sum_i \\sum_j v_iw_{ij}h_{j} \\\\ =−\\mathbf{a}^T\\mathbf{v}−\\mathbf{b}^T\\mathbf{h}−\\mathbf{v}^TW\\mathbf{h}\r$$\rThe joint probability $p(v,h)$ is defined as follows $$\rp(\\mathbf{v},\\mathbf{h}) =\\frac{1}{Z} exp⁡(−E(\\mathbf{v},\\mathbf{h}))=\\frac{1}{Z} exp⁡(\\mathbf{a}^T\\mathbf{v})exp⁡(\\mathbf{b}^T\\mathbf{h})exp⁡(\\mathbf{v}^TW\\mathbf{h})\r$$\rWhere $Z=\\sum_{\\mathbf{v},\\mathbf{h}} exp⁡(−E(\\mathbf{v},\\mathbf{h}))$ is the partition function\nGood property of RBM: No connection between hidden units nor between visible units; thus given visible variables, hidden variables are independent with each other, and vice versa. $$\rp(v_i│\\mathbf{V}_{\\backslash i}, \\mathbf{h})=p(v_i│\\mathbf{h}); p(h_i│\\mathbf{v},\\mathbf{h}_{\\backslash i})=p(v_i│\\mathbf{v})\r$$\r$$\rp(v_i=1│\\mathbf{h})=σ(\\sum_j w_{ij} h_i+a_i); p(ℎ_i=1│\\mathbf{v})=\\sigma(\\sum_j w_{ij} v_i+b_i)\r$$\rStill we have the same 2 problems as the Boltzmann Machines Problem 1: How to reach equilibrium?\nStill we can use Gibbs Sampling Sampling Procedure:\n(Given or) Randomly initiate a visible …","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"f98b9e5506e77ad36da7563ae9ec170b","permalink":"https://yanko96.github.io/slides/dbm/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/dbm/","section":"slides","summary":"Deep Bolzmann Machine","tags":["Machine Learning","Bolzmann Machine"],"title":"Slides","type":"slides"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://yanko96.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]